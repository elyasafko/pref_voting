{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pref_voting.dominance_axioms import condorcet_winner, condorcet_loser, pareto_dominance\n",
    "from pref_voting.profiles import _find_updated_profile\n",
    "from pref_voting.pairwise_profiles import *\n",
    "from pref_voting.voting_methods import *\n",
    "from pref_voting.generate_profiles import *\n",
    "from pref_voting.voting_methods_registry import voting_methods\n",
    "from pref_voting.generate_weighted_majority_graphs import *\n",
    "from pref_voting.helper import *\n",
    "from pref_voting.mappings import *  \n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import permutations\n",
    "from pref_voting.axioms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<networkx.classes.digraph.DiGraph object at 0x2c2a4b450>, <networkx.classes.digraph.DiGraph object at 0x2c2a4b410>]\n"
     ]
    }
   ],
   "source": [
    "mg = MarginGraph(\n",
    "    [0, 1, 2, 3], \n",
    "    [\n",
    "        (0, 1, 10), \n",
    "        (0, 2, 2), \n",
    "        (1, 3, 4), \n",
    "        (2, 1, 6), \n",
    "        (2, 3, 8), \n",
    "        (3, 0, 4)]\n",
    "        )\n",
    "\n",
    "rp_defeats = ranked_pairs_defeats(mg)\n",
    "\n",
    "print(rp_defeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = ProfileWithTies([\n",
    "    {0: 1, 2: 1, 1: 2, 3: 2}, \n",
    "    {3: 1, 0: 2, 1: 3, 2: 4}, \n",
    "    {2: 1, 1: 1, 3: 1}, \n",
    "    {3: 1, 0: 2, 1: 3, 2: 4}, \n",
    "    {1: 1, 2: 2}, \n",
    "    {}, \n",
    "    {3: 2, 1: 3, 2: 4}], \n",
    "    rcounts=[1, 1, 1, 1, 1, 1, 1], \n",
    "    cmap={0: 'a', 1: 'b', 2: 'c', 3: 'd'})\n",
    "\n",
    "prof = ProfileWithTies([{}], rcounts=[100], cmap={0: 'a', 1: 'b', 2: 'c', 3: 'd'})\n",
    "prof.display()\n",
    "\n",
    "print(prof.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_quarto(prof, cmap = None, curr_cands = None):\n",
    "\n",
    "    cmap = cmap if cmap is not None else prof.cmap\n",
    "    rankings = prof._rankings if curr_cands is None else _find_updated_profile(prof._rankings, np.array([c for c in prof.candidates if c not in curr_cands]), len(prof.candidates))\n",
    "    \n",
    "    cs = 'c' * len(prof._rcounts)\n",
    "    \n",
    "    latex_str = \"\\\\begin{array}{\" + str(cs) + \"}\\n\"\n",
    "    latex_str += \" & \".join([f\"{rc}\" for rc in prof._rcounts]) + \"\\\\\\\\\\hline \\n\"\n",
    "    latex_str +=  \"\\\\\\\\ \\n\".join([\" & \".join([f\"{cmap[c]}\" for c in cs])  for cs in rankings.transpose()])\n",
    "    latex_str += \"\\n\\\\end{array}\"\n",
    "    \n",
    "    return latex_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "for t in range(10): \n",
    "\n",
    "    num_cands = random.choice([3, 4, 4, 4])\n",
    "\n",
    "    prof = generate_profile(num_cands, 50)\n",
    "\n",
    "    cmap = {0: 'a', 1: 'b', 2: 'c', 3: 'd'}\n",
    "\n",
    "    num_rankings = random.choice([3, 4, 5, 6])\n",
    "    prof_smaller = Profile(prof.anonymize().ranking_types[0:num_rankings], list(prof.anonymize()._rcounts)[0:num_rankings], cmap=cmap)\n",
    "\n",
    "    prof_smaller.display()\n",
    "\n",
    "    prof_smaller.display_margin_graph()\n",
    "    print(to_quarto(prof_smaller, cmap=cmap))\n",
    "\n",
    "    for c1, c2 in combinations(prof_smaller.candidates, 2):\n",
    "        print(f\"* The margin of ${cmap[c1]}$ over ${cmap[c2]}$ is ${prof_smaller.support(c1, c2)} - {prof_smaller.support(c2, c1)} = {prof_smaller.margin(c1, c2)}$\")\n",
    "        print(f\"* The margin of ${cmap[c2]}$ over ${cmap[c1]}$ is ${prof_smaller.support(c2, c1)} - {prof_smaller.support(c1, c2)} = {prof_smaller.margin(c2, c1)}$\")\n",
    "\n",
    "    print(\"\\nThe margin graph is:\")\n",
    "    print(prof_smaller.margin_graph().to_latex(cmap=cmap))\n",
    "\n",
    "print(\"\\n\\n--------\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = generate_margin_graph(5)\n",
    "mg.display()\n",
    "mg.debord_profile().display()\n",
    "mg.minimal_profile().display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cands = 4\n",
    "num_voters = 5\n",
    "a=0\n",
    "b=1\n",
    "c=2\n",
    "d=3\n",
    "e=4\n",
    "cmap = {a: 'a', b: 'b', c: 'c', d: 'd', e: 'e'}\n",
    "\n",
    "num_trials = 1000000\n",
    "\n",
    "for t in range(num_trials): \n",
    "    prof = generate_profile(num_cands, num_voters)\n",
    "    rankings = prof.rankings\n",
    "\n",
    "    if len(rankings) == 5:\n",
    "        v1_ranking = rankings[0]\n",
    "        borda_ws = borda(prof)\n",
    "        if len(borda_ws) == 2 and  v1_ranking[0] in borda_ws and v1_ranking[3] in borda_ws:\n",
    "\n",
    "            margins = list(set([prof.margin(c1, c2) for c1 in prof.candidates for c2 in prof.candidates if prof.majority_prefers(c1, c2)]))\n",
    "\n",
    "            if len(margins) >= 3: \n",
    "                for new_ranking in permutations(prof.candidates):\n",
    "                    new_prof = Profile([new_ranking] + rankings[1:])\n",
    "                    new_borda_ws = borda(new_prof)\n",
    "                    if (len(new_borda_ws)==2 and v1_ranking[1] in new_borda_ws and v1_ranking[2] in new_borda_ws) or (len(new_borda_ws)==1 and v1_ranking[1] in new_borda_ws):\n",
    "                        print(margins)\n",
    "                        print(prof)\n",
    "                        print(prof.to_latex(cmap=cmap))\n",
    "                        print(new_ranking)\n",
    "                        print(new_prof.to_latex(cmap=cmap))\n",
    "                        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cands = 5\n",
    "num_voters = 4\n",
    "\n",
    "a=0\n",
    "b=1\n",
    "c=2\n",
    "d=3\n",
    "e=4\n",
    "cmap = {a: 'a', b: 'b', c: 'c', d: 'd', e: 'e'}\n",
    "\n",
    "\n",
    "for _prof in enumerate_anon_profile(num_cands, num_voters):\n",
    "    prof = _prof.anonymize()\n",
    "    rankings = prof.rankings\n",
    "\n",
    "    if True or len(rankings) == 5:\n",
    "        v1_ranking = rankings[0]\n",
    "        borda_ws = borda(prof)\n",
    "        if len(borda_ws) == 2 and  v1_ranking[0] in borda_ws and v1_ranking[4] in borda_ws:\n",
    "        # if len(borda_ws) == 1 and  v1_ranking[1] in borda_ws:\n",
    "\n",
    "            margins = list(set([prof.margin(c1, c2) for c1 in prof.candidates for c2 in prof.candidates if prof.majority_prefers(c1, c2)]))\n",
    "\n",
    "            if len(margins) >= 2: \n",
    "                found_it = False\n",
    "                for new_ranking in permutations(prof.candidates):\n",
    "                    new_prof = Profile([new_ranking] + rankings[1:])\n",
    "                    new_borda_ws = borda(new_prof)\n",
    "                    # if (len(new_borda_ws)==2 and v1_ranking[1] in new_borda_ws and v1_ranking[2] in new_borda_ws):\n",
    "                    if (len(new_borda_ws)==2 and v1_ranking[1] in new_borda_ws and v1_ranking[2] in new_borda_ws) or (len(new_borda_ws)==2 and v1_ranking[2] in new_borda_ws and v1_ranking[3] in new_borda_ws):\n",
    "                    # if (len(new_borda_ws)==2 and v1_ranking[0] in new_borda_ws and v1_ranking[2] in new_borda_ws) or (len(new_borda_ws)==2 and v1_ranking[0] in new_borda_ws and v1_ranking[3] in new_borda_ws):\n",
    "                        print(margins)\n",
    "                        print(prof)\n",
    "                        print(borda_ws)\n",
    "                        print(prof.to_latex(cmap=cmap))\n",
    "                        print(new_ranking)\n",
    "                        print(new_borda_ws)\n",
    "                        print(new_prof.to_latex(cmap=cmap))\n",
    "                        found_it = False\n",
    "                        break\n",
    "            if found_it:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=0\n",
    "b=1\n",
    "c=2\n",
    "d=3\n",
    "cmap = {a: 'a', b: 'b', c: 'c', d: 'd'}\n",
    "orig_prof = Profile([\n",
    "    [c, b, a, d], \n",
    "    [c, b, d, a], \n",
    "    [c, b, d, a], \n",
    "    [d, b, a, c],\n",
    "    [d, b, a, c],\n",
    "], cmap=cmap)\n",
    "orig_prof.display()\n",
    "    \n",
    "mg = orig_prof.margin_graph()\n",
    "mg.display()\n",
    "print(mg.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=0\n",
    "b=1\n",
    "c=2\n",
    "d=3\n",
    "cmap = {a: 'a', b: 'b', c: 'c', d: 'd'}\n",
    "orig_prof = Profile([\n",
    "    [c, b, a, d], \n",
    "    [c, b, d, a], \n",
    "    [c, b, d, a], \n",
    "    [d, b, a, c],\n",
    "    [d, b, a, c],\n",
    "], cmap=cmap)\n",
    "orig_prof.display()\n",
    "\n",
    "borda_ws = borda(orig_prof)\n",
    "print(borda_ws)\n",
    "\n",
    "for t in range(20): \n",
    "    _prof = generate_profile(4, 5)\n",
    "    rankings = list(_prof.rankings)  \n",
    "    if len(rankings) == 5: \n",
    "        prof = Profile([\n",
    "            [c, b, a, d]\n",
    "        ] + rankings[1:], cmap=cmap)\n",
    "        new_borda_ws = borda(prof)\n",
    "        if borda_ws == new_borda_ws:\n",
    "            print('Match')\n",
    "            print(prof)\n",
    "            print(prof.to_latex())  \n",
    "\n",
    "            print(\"\\n--------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(100): \n",
    "    _prof = generate_profile(4, 5)\n",
    "    rankings = list(_prof.rankings)  \n",
    "    if len(rankings) == 5: \n",
    "        prof = Profile([\n",
    "            [c, b, a, d]\n",
    "        ] + rankings[1:], cmap=cmap)\n",
    "        maj_g = prof.majority_graph()\n",
    "        orig_maj_g = orig_prof.majority_graph()\n",
    "        if maj_g == orig_maj_g:\n",
    "            print('Match')\n",
    "            maj_g.display()\n",
    "            print(prof.to_latex())  \n",
    "            print(\"\\n-------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=0\n",
    "b=1\n",
    "c=2\n",
    "d=3\n",
    "cmap = {a: 'a', b: 'b', c: 'c', d: 'd'}\n",
    "orig_prof = Profile([\n",
    "    [c, b, a, d], \n",
    "    [d, b, a, c], \n",
    "    [b, c, a, d],\n",
    "    [b, d, a, c],\n",
    "    [b, c, a, d]\n",
    "], cmap=cmap)\n",
    "\n",
    "print(orig_prof.to_latex())\n",
    "orig_prof.display()\n",
    "    \n",
    "mg = orig_prof.margin_graph()\n",
    "mg.display()\n",
    "print(mg.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(100000): \n",
    "    _prof = generate_profile(4, 5)\n",
    "    rankings = list(_prof.rankings)  \n",
    "    if True or len(rankings) == 5: \n",
    "        prof = Profile([\n",
    "            [c, b, a, d]\n",
    "        ] + rankings[1:], cmap=cmap)\n",
    "        mg = prof.margin_graph()\n",
    "        orig_maj_g = orig_prof.margin_graph()\n",
    "        if mg == orig_maj_g:\n",
    "            print('Match')\n",
    "            mg.display()\n",
    "            print(prof.to_latex())  \n",
    "\n",
    "            print(\"\\n----------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _revealed_weak_preference(c1, c2, menu, choice): \n",
    "    \"\"\"Returns the revealed weak preference of a menu of choices. \n",
    "    \"\"\"\n",
    "\n",
    "    return c1 in menu and c2 in menu and c1 in choice\n",
    "\n",
    "def _revealed_strict_preference(c1, c2, menu, choice): \n",
    "    \"\"\"Returns the revealed strict preference of a menu of choices. \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return _revealed_weak_preference(c1, c2, menu, choice) and not _revealed_weak_preference(c2, c1, menu, choice)\n",
    "\n",
    "def _revealed_indifference(c1, c2, menu, choice): \n",
    "    \"\"\"Returns the revealed indifference of a menu of choices. \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return _revealed_weak_preference(c1, c2, menu, choice) and  _revealed_weak_preference(c2, c1, menu, choice)\n",
    "\n",
    "print( {1, 2}, {1, 2})\n",
    "print(_revealed_weak_preference(1, 2, {1, 2}, {1, 2}))\n",
    "print(_revealed_weak_preference(2, 1, {1, 2}, {1, 2}))\n",
    "\n",
    "print(_revealed_strict_preference(1, 2, {1, 2}, {1, 2}))\n",
    "print(_revealed_strict_preference(2, 1, {1, 2}, {1, 2}))\n",
    "print(_revealed_indifference(1, 2, {1, 2}, {1, 2}))\n",
    "print(_revealed_indifference(2, 1, {1, 2}, {1, 2}))\n",
    "\n",
    "print( {1, 2}, {1})\n",
    "print(_revealed_weak_preference(1, 2, {1, 2}, {1}))\n",
    "print(_revealed_weak_preference(2, 1, {1, 2}, {1}))\n",
    "print(_revealed_strict_preference(1, 2, {1, 2}, {1}))\n",
    "print(_revealed_strict_preference(2, 1, {1, 2}, {1}))\n",
    "print(_revealed_indifference(1, 2, {1, 2}, {1}))\n",
    "print(_revealed_indifference(2, 1, {1, 2}, {1}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons1 = [({\"A\", \"B\"}, {\"A\"}), ({\"A\", \"C\"}, {\"C\"}), ({\"B\", \"C\"}, {\"B\"})]\n",
    "comparisons2 = [({\"A\", \"B\"}, {\"B\"}), ({\"A\", \"C\"}, {\"A\"}), ({\"B\", \"C\"}, {\"C\"})]\n",
    "pprof = PairwiseProfile([PairwiseComparisons(comparisons1), PairwiseComparisons(comparisons2)], rcounts=[3,2])\n",
    "\n",
    "pprof.display()\n",
    "\n",
    "pprof.margin_graph().display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_pcomps = [(0, 1), (2, 1), ({0, 2}, {0, 2})]\n",
    "pcomps = PairwiseComparisons(_pcomps)\n",
    "print(pcomps.is_coherent())\n",
    "pcomps.display()\n",
    "print(pcomps)\n",
    "print(\"pcomps.weak_preference(0, 1)\", pcomps.weak_preference(0, 1))\n",
    "print(\"pcomps.weak_preference(1, 0)\", pcomps.weak_preference(1, 0))\n",
    "print(\"pcomps.strict_preference(0, 1)\", pcomps.strict_preference(0, 1))\n",
    "print(\"pcomps.strict_preference(1, 0)\", pcomps.strict_preference(1, 0))\n",
    "print(\"pcomps.indifference(0, 1)\", pcomps.indifference(0, 1))   \n",
    "print(\"pcomps.indifference(1, 0)\", pcomps.indifference(1, 0))\n",
    "\n",
    "print(\"pcomps.weak_preference(0, 2)\", pcomps.weak_preference(0, 2))\n",
    "print(\"pcomps.weak_preference(2, 0)\", pcomps.weak_preference(2, 0))\n",
    "print(\"pcomps.strict_preference(0, 2)\", pcomps.strict_preference(0, 2))\n",
    "print(\"pcomps.strict_preference(2, 0)\", pcomps.strict_preference(2, 0))\n",
    "print(\"pcomps.indifference(0, 2)\", pcomps.indifference(0, 2))   \n",
    "print(\"pcomps.indifference(2, 0)\", pcomps.indifference(2, 0))\n",
    "\n",
    "\n",
    "print(\"pcomps.weak_preference(3, 4)\", pcomps.weak_preference(3, 4))\n",
    "print(\"pcomps.strict_preference(3, 4)\", pcomps.strict_preference(3, 4))\n",
    "print(\"pcomps.indifference(3, 4)\", pcomps.indifference(3, 4))   \n",
    "\n",
    "print(\"pcomps.has_comparison(0, 1)\", pcomps.has_comparison(0, 1))\n",
    "print(\"pcomps.has_comparison(1, 0)\", pcomps.has_comparison(1, 0))\n",
    "print(\"pcomps.has_comparison(0, 2)\", pcomps.has_comparison(0, 2))\n",
    "print(\"pcomps.has_comparison(2, 0)\", pcomps.has_comparison(2, 0))\n",
    "print(\"pcomps.has_comparison(3, 4)\", pcomps.has_comparison(3, 4))\n",
    "print(\"pcomps.has_comparison(2, 4)\", pcomps.has_comparison(2, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprof = PairwiseProfile([\n",
    "    [[{0, 1}, {1}], (3, 2)], \n",
    "    [[{0, 2}, {2, 0}], [{0, 1}, {1}]]], \n",
    "    rcounts=[3, 2])\n",
    "\n",
    "print(pprof)\n",
    "\n",
    "pprof.display()\n",
    "print(pprof.candidates)\n",
    "print(pprof._pairwise_comparisons)\n",
    "print(pprof._tally)\n",
    "for c in pprof.candidates:\n",
    "    for d in pprof.candidates:\n",
    "        print(f'margin({c}, {d}) = {pprof.margin(c,d)}') \n",
    "\n",
    "print(pprof.condorcet_winner())\n",
    "\n",
    "print(pprof.condorcet_loser())  \n",
    "pprof.margin_graph().display()\n",
    "\n",
    "split_cycle.display(pprof.margin_graph())\n",
    "\n",
    "bradley_terry.display(pprof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations = superior_voting.get_violation_witness(\"condorcet_winner\")\n",
    "\n",
    "for prof_type, prof in violations.items():\n",
    "    if prof is not None:\n",
    "        print(prof_type)\n",
    "        print(prof)\n",
    "        condorcet_winner.has_violation(prof, superior_voting, verbose=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vm in voting_methods.filter(violates=[\"condorcet_winner\"], election_types=[ElectionTypes.PROFILE]):\n",
    "    print(vm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vm in voting_methods: \n",
    "    print(vm)\n",
    "    elections = vm.get_violation_witness(\"condorcet_winner\")\n",
    "    for prof_type, prof in elections.items():\n",
    "        if prof is not None:\n",
    "            print(prof_type)\n",
    "            condorcet_winner.has_violation(prof, vm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vm in voting_methods:\n",
    "    print(vm.__name__)\n",
    "    print(vm.name)\n",
    "    print(vm.properties.items())\n",
    "    print(vm.get_properties())\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(axioms_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = generate_profile(5, 10)\n",
    "prof.display()\n",
    "\n",
    "print(prof.margin(0, 4))\n",
    "\n",
    "pickle.dump(prof, open(\"profile.pkl\", \"wb\"))\n",
    "prof = pickle.load(open(\"profile.pkl\", \"rb\"))\n",
    "prof.display()\n",
    "\n",
    "print(prof.margin(0, 4))\n",
    "\n",
    "\n",
    "for vm in voting_methods:\n",
    "    print(vm.name)\n",
    "    if ElectionTypes.PROFILE in vm.input_types:\n",
    "        print(vm(prof))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = [2, 0, 5, 4, 3, 1]\n",
    "u = Utility.from_linear_ranking(r, seed=42)\n",
    "print(u)\n",
    "u.ranking().to_linear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = generate_profile(3, 2, seed=42)\n",
    "\n",
    "prof.display()\n",
    "\n",
    "uprof = prof.to_utility_profile()\n",
    "\n",
    "uprof.display()\n",
    "\n",
    "uprof.to_ranking_profile().to_linear_profile().display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "        \n",
    "utilities = sorted(rng.random(size=6), reverse=True)\n",
    "print(utilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = ProfileWithTies([\n",
    "    {'a': 1, 'b': 2, 'c': 3},\n",
    "    {'a': 2, 'b': 1, 'c': 3},\n",
    "    {'a': 3, 'b': 2, 'c': 1},\n",
    "    {'a': 3},\n",
    "    {'a': 2, 'b': 3, 'c': 1},\n",
    "    {'a': 1, 'b': 3},\n",
    "])\n",
    "\n",
    "prof.display()\n",
    "\n",
    "split_cycle.display(prof)\n",
    "split_cycle.display(prof, algorithm='basic_parallel')\n",
    "\n",
    "split_cycle.display(prof, curr_cands = ['b', 'c'])\n",
    "\n",
    "split_cycle.display(prof, algorithm='basic_parallel', curr_cands = ['b', 'c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for t in tqdm(range(1000)): \n",
    "\n",
    "    prof = generate_profile(random.choice([4, 5, 10, 15]),random.choice([5, 10, 100, 1001]))\n",
    "    sc_ws = split_cycle(prof)\n",
    "    sc_ws_parallel = split_cycle(prof, algorithm='basic_parallel')\n",
    "\n",
    "    if sc_ws != sc_ws_parallel:\n",
    "        print(prof)\n",
    "        print(sc_ws)\n",
    "        print(sc_ws_parallel)\n",
    "        print(\"Error\")\n",
    "        break\n",
    "\n",
    "    sc_ws = split_cycle(prof, curr_cands = [1, 2, 3])\n",
    "    sc_ws_parallel = split_cycle(prof, curr_cands = [1, 2, 3], algorithm='basic_parallel')\n",
    "\n",
    "    if sc_ws != sc_ws_parallel:\n",
    "        print(prof)\n",
    "        print(sc_ws)\n",
    "        print(sc_ws_parallel)\n",
    "        print(\"Error\")\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profs = [generate_edge_ordered_tournament(500) for _ in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(len([split_cycle(mg) for mg in profs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(len([split_cycle(mg, algorithm='basic_parallel', num_cpus=8) for mg in profs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "print(len([split_cycle(prof, algorithm='floyd_warshall') for prof in profs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_cycle.set_algorithm(\"floyd_warshall\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of voting methods \", len(list(voting_methods)))\n",
    "\n",
    "print(\"Total number of voting methods accepting Profile \", len(voting_methods.filter(election_types=[ElectionTypes.PROFILE])))\n",
    "\n",
    "print(\"Total number of Condorcet Consistent voting methods \", len(voting_methods.filter(satisfies=[\"condorcet_winner\"])))\n",
    "\n",
    "print(\"Total number of voting methods satisfying condorcet_winner and condorcet_loser\", len(voting_methods.filter(satisfies=[\"condorcet_winner\", \"condorcet_loser\"])))\n",
    "\n",
    "print(\"Total number of voting methods satisfying pareto_dominance\", len(voting_methods.filter(satisfies=[\"pareto_dominance\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the function name of the voting method\n",
    "#print(voting_methods.get(\"borda\").name)\n",
    "# not the name parameter but rather the name of the function\n",
    "print(borda.vm.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vm in voting_methods: \n",
    "    print(vm.name)\n",
    "    print(voting_methods.method_type(vm.name))    \n",
    "    print(voting_methods.file_location(vm.name))\n",
    "\n",
    "    filename = voting_methods.file_location(vm.name).split(\".\")[0]\n",
    "    print(f\"https://pref-voting.readthedocs.io/en/latest/{filename}.html#pref_voting.{filename}.{vm.vm.__name__}\")\n",
    "    #scoring_methods.html#pref_voting.scoring_methods.scoring_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of voting methods \", len(voting_methods))\n",
    "\n",
    "print(\"Total number of voting methods accepting TruncatedLinearOrders \", len(voting_methods.filter(election_types=[ElectionTypes.TRUNCATED_LINEAR_PROFILE])))\n",
    "\n",
    "print(\"Total number of voting methods accepting MarginGraph \", len(voting_methods.filter(election_types=[ElectionTypes.MARGIN_GRAPH])))\n",
    "\n",
    "print(\"Total number of voting methods accepting MajorityGraph \", len(voting_methods.filter(election_types=[ElectionTypes.MAJORITY_GRAPH])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_methods.display_methods()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = generate_profile(4, 5)\n",
    "for vm in voting_methods:\n",
    "    print(vm)\n",
    "    if ElectionTypes.PROFILE in vm.input_types:\n",
    "        vm.display(prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vmidx,vm in enumerate(voting_methods): \n",
    "    print(f\"{vmidx+1}. {vm}\")\n",
    "    vm.save_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for t in range(10000): \n",
    "    prof = generate_profile(10, 100)\n",
    "    if pareto_dominance.has_violation(prof,superior_voting, verbose=True): \n",
    "        print(prof)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pref_voting.swf_axioms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R=0\n",
    "D=1\n",
    "P=2\n",
    "prof = Profile([\n",
    "    [R, D, P],\n",
    "    [P, D, R],\n",
    "    [D, P, R]\n",
    "], \n",
    "[40, 35, 25],\n",
    ")\n",
    "\n",
    "prof.display()\n",
    "\n",
    "plurality.display(prof)\n",
    "instant_runoff.display(prof)\n",
    "split_cycle.display(prof)\n",
    "\n",
    "sc_ranking = swf_from_vm(split_cycle)\n",
    "\n",
    "@swf(\"DPR\")\n",
    "def dpr(profile, curr_cands=None):\n",
    "    return Ranking({D: 1, P: 2, R: 3})\n",
    "@swf(\"DRP\")\n",
    "def drp(profile, curr_cands=None):\n",
    "    return Ranking({D: 1, P: 3, R: 2})\n",
    "@swf(\"RPD\")\n",
    "def rpd(profile, curr_cands=None):\n",
    "    return Ranking({D: 3, P: 2, R: 1})\n",
    "@swf(\"RDP\")\n",
    "def rdp(profile, curr_cands=None):\n",
    "    return Ranking({D: 2, P: 3, R: 1})\n",
    "@swf(\"PDR\")\n",
    "def pdr(profile, curr_cands=None):\n",
    "    return Ranking({D: 2, P: 1, R: 3})\n",
    "@swf(\"PRD\")\n",
    "def prd(profile, curr_cands=None):\n",
    "    return Ranking({D: 3, P: 1, R: 2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instant_runoff_ranking.display(prof)\n",
    "\n",
    "irv_swf2 = swf_from_vm(instant_runoff)\n",
    "irv_swf2.display(prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_support.find_all_violations(prof.anonymize(),pdr, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_support.has_violation(prof.anonymize(),drp, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "borda.get_properties()\n",
    "\n",
    "borda.add_property(\"condorcet_winner\", False)\n",
    "borda.save_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
